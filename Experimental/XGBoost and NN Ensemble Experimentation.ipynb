{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility across multiple platforms\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "# Load files using DictReader in Python\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from ultimate.mlp import MLP \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_filepath = \"pubg-finish-placement-prediction/train_V2_clean.csv\"\n",
    "\n",
    "#trainset_file = open(train_filepath,'rU')\n",
    "trainset = pd.read_csv(train_filepath,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_two(moddedTrain):\n",
    "    moddedTrain['playersJoined'] = moddedTrain.groupby('matchId')['matchId'].transform('count')\n",
    "    moddedTrain['killsNorm'] = moddedTrain['kills']*((100-moddedTrain['playersJoined'])/100 + 1)\n",
    "    moddedTrain['damageDealtNorm'] = moddedTrain['damageDealt']*((100-moddedTrain['playersJoined'])/100 + 1)\n",
    "    moddedTrain['maxPlaceNorm'] = moddedTrain['maxPlace']*((100-moddedTrain['playersJoined'])/100 + 1)\n",
    "    moddedTrain['matchDurationNorm'] = moddedTrain['matchDuration']*((100-moddedTrain['playersJoined'])/100 + 1)\n",
    "    moddedTrain['healsandboosts'] = moddedTrain['heals'] + moddedTrain['boosts']\n",
    "    moddedTrain['totalDistance'] = moddedTrain['rideDistance'] + moddedTrain['walkDistance'] + moddedTrain['swimDistance']\n",
    "    moddedTrain['killsWithoutMoving'] = ((moddedTrain['kills'] > 0) & (moddedTrain['totalDistance'] == 0))\n",
    "    moddedTrain['headshot_rate'] = moddedTrain['headshotKills'] / moddedTrain['kills']\n",
    "    moddedTrain['headshot_rate'] = moddedTrain['headshot_rate'].fillna(0)\n",
    "    moddedTrain.drop(moddedTrain[moddedTrain['killsWithoutMoving'] == True].index, inplace=True)\n",
    "    moddedTrain.drop(moddedTrain[moddedTrain['roadKills'] > 8].index, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(trainset,is_train=True):\n",
    "    # When this function is used for the training data, load train_V2.csv :\n",
    "    if is_train: \n",
    "        print(\"processing train_V2.csv\")\n",
    "        #df = pd.read_csv(\"pubg-finish-placement-prediction/train_V2_clean.csv\",index_col=0)\n",
    "        df = trainset\n",
    "        # Only take the samples with matches that have more than 1 player \n",
    "        # there are matches with no players or just one player ( those samples could affect our model badly) \n",
    "        df = df[df['maxPlace'] > 1]\n",
    "    \n",
    "    # When this function is used for the test data, load test_V2.csv :\n",
    "    else:\n",
    "        print(\"processing test_V2.csv\")\n",
    "        df = pd.read_csv(INPUT_DIR + 'test_V2.csv')\n",
    "        \n",
    "    # Make a new feature indecating the total distance a player cut :\n",
    " \n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "\n",
    "    # Process the 'rankPoints' feature by replacing any value of (-1) to be (0) :\n",
    "    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])\n",
    "                           \n",
    "    \n",
    "\n",
    "    target = 'winPlacePerc'\n",
    "    # Get a list of the features to be used\n",
    "    features = list(df.columns)\n",
    "    \n",
    "    # Remove some features from the features list :\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchDuration\")\n",
    "    features.remove(\"matchType\")\n",
    "    \n",
    "    y = None\n",
    "    \n",
    "    # If we are processing the training data, process the target\n",
    "    # (group the data by the match and the group then take the mean of the target) \n",
    "    if is_train: \n",
    "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
    "        # Remove the target from the features list :\n",
    "        features.remove(target)\n",
    "    \n",
    "    # Make new features indicating the mean of the features ( grouped by match and group ) :\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    \n",
    "    # If we are processing the training data let df_out = the grouped  'matchId' and 'groupId'\n",
    "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    # If we are processing the test data let df_out = 'matchId' and 'groupId' without grouping \n",
    "    else: df_out = df[['matchId','groupId']]\n",
    "    \n",
    "    # Merge agg and agg_rank (that we got before) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the max value of the features for each group ( grouped by match )\n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the minimum value of the features for each group ( grouped by match )\n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the number of players in each group ( grouped by match )\n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "     \n",
    "    # Merge the group_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the mean value of each features for each match :\n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    \n",
    "    # Merge the new agg with df_out :\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    # Make new features indicating the number of groups in each match :\n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    \n",
    "    # Merge the match_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    # Drop matchId and groupId\n",
    "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "    \n",
    "    y = y.tolist()\n",
    "    \n",
    "\n",
    "    return df_out,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_engineering_two(trainset)\n",
    "df_out,y = feature_engineering(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(df_out, y , test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# SET UP FOR MODEL ONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the trainset features for tree one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = x_train\n",
    "y_one = y_train\n",
    "\n",
    "x_one_val = x_val\n",
    "y_one_val = y_val\n",
    "\n",
    "\n",
    "#set the dmatrix\n",
    "#trainset_one_dmatrix = xgb.DMatrix(x_one.values,label=y_train.values,feature_names=x_one.columns)\n",
    "#valset_one_dmatrix = xgb.DMatrix(x_one_val.values,label=y_one_val.values,feature_names=x_one_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_one_dmatrix = xgb.DMatrix(x_one.values,label=y_train,feature_names=x_one.columns)\n",
    "valset_one_dmatrix = xgb.DMatrix(x_one_val.values,label=y_one_val,feature_names=x_one_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_one.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure tree one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\" : 7,\n",
    "    \"eval_metric\" : [\"mae\"],\n",
    "    \"lambda\": 1.1,   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iters = 30\n",
    "\n",
    "tree_one = xgb.train(params, trainset_one_dmatrix, evals=[(trainset_one_dmatrix, \"train\"),(valset_one_dmatrix, 'val')], num_boost_round = iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb.plot_importance(tree_one,importance_type='cover')\n",
    "xgb.plot_importance(tree_one,importance_type='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET UP FOR MODEL TWO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the trainset features for tree two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_two = x_train\n",
    "y_two = y_train\n",
    "\n",
    "x_two_val = x_val\n",
    "y_two_val = y_val\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(x_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaler.transform(x_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create NN_model\n",
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(x_two.shape[1],  input_dim = x_two.shape[1], activation='relu'))\n",
    "NN_model.add(Dense(136, activation='relu'))\n",
    "NN_model.add(BatchNormalization())\n",
    "NN_model.add(Dense(136, activation='relu'))\n",
    "NN_model.add(Dense(136, activation='relu'))\n",
    "NN_model.add(Dense(136, activation='relu'))\n",
    "NN_model.add(Dense(100, activation='relu'))\n",
    "NN_model.add(Dense(100, activation='relu'))\n",
    "NN_model.add(Dense(100, activation='relu'))\n",
    "NN_model.add(Dense(100, activation='relu'))\n",
    "NN_model.add(Dense(80, activation='relu'))\n",
    "NN_model.add(Dense(80, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# output Layer\n",
    "NN_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NN_model.fit(x=x_two, y=y_two, batch_size=1000,\n",
    "             epochs=20, verbose=1, callbacks=callbacks_list,\n",
    "             validation_split=0.20, validation_data=None, shuffle=True,\n",
    "             class_weight=None, sample_weight=None, initial_epoch=0,\n",
    "             steps_per_epoch=None, validation_steps=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSENBLE MODELS ON VALSET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict - Update - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_predictions(models,labels,num_samples):\n",
    "    labels = labels[:num_samples]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        data = model['data']\n",
    "        predictor = model['predictor']\n",
    "\n",
    "        if model['type'] == \"tree\":\n",
    "            matrix = xgb.DMatrix(data,feature_names=data.columns)\n",
    "            prediction = predictor.predict(matrix)\n",
    "            predictions.append(prediction)\n",
    "            print(\"tree\")\n",
    "        if model['type'] == \"nn\":\n",
    "            prediction = predictor.predict(data)\n",
    "            predictions.append(prediction)\n",
    "            print(\"nn\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        \n",
    "    print(len(predictions[0]))\n",
    "    print(len(predictions[1]))\n",
    "\n",
    "    avg_predictions = [0.0]*len(predictions[0])\n",
    "    weight = 0\n",
    "    for j in range(len(predictions[0])):\n",
    "        if predictions[0][j] - predictions[1][j] <= .0001:\n",
    "            avg_predictions[j] = 1.0 * (predictions[0][j] + predictions[1][j]) / 2.0\n",
    "        else:\n",
    "            avg_predictions[j] = predictions[0][j]\n",
    "\n",
    "    print(len(avg_predictions))\n",
    "    return avg_predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append({'data':x_one_val,\n",
    "                'predictor':NN_model,\n",
    "                'type':\"nn\"})\n",
    "\n",
    "models.append({'data':x_one_val,\n",
    "                'predictor':tree_one,\n",
    "                'type':\"tree\"})\n",
    "\n",
    "labels = y_val\n",
    "\n",
    "num_samples = 200000\n",
    "\n",
    "predictions = gen_predictions(models,labels,num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.mean_absolute_error(labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.mean_absolute_error(labels,tree_one.predict(valset_one_dmatrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
