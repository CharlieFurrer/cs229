{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility across multiple platforms\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "# Load files using DictReader in Python\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zac_farnsworth95/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_filepath = \"pubg-finish-placement-prediction/train_V2_clean.csv\"\n",
    "\n",
    "#trainset_file = open(train_filepath,'rU')\n",
    "trainset = pd.read_csv(train_filepath,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4446965\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Matchtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = trainset.drop([\"matchType\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a feature for the number of players joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either drop the matchtype or one-hot encode it. Dropping it works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moddedTrain = pd.get_dummies(moddedTrain, columns=['matchType'])\n",
    "#moddedTrain = moddedTrain.drop([\"matchType\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(is_train=True):\n",
    "    # When this function is used for the training data, load train_V2.csv :\n",
    "    if is_train: \n",
    "        print(\"processing train_V2.csv\")\n",
    "        df = pd.read_csv(\"pubg-finish-placement-prediction/train_V2_clean.csv\",index_col=0)\n",
    "        \n",
    "        # Only take the samples with matches that have more than 1 player \n",
    "        # there are matches with no players or just one player ( those samples could affect our model badly) \n",
    "        df = df[df['maxPlace'] > 1]\n",
    "    \n",
    "    # When this function is used for the test data, load test_V2.csv :\n",
    "    else:\n",
    "        print(\"processing test_V2.csv\")\n",
    "        df = pd.read_csv(INPUT_DIR + 'test_V2.csv')\n",
    "        \n",
    "    # Make a new feature indecating the total distance a player cut :\n",
    " \n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "\n",
    "    # Process the 'rankPoints' feature by replacing any value of (-1) to be (0) :\n",
    "    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])\n",
    "    \n",
    "    df['playersJoined'] = df.groupby('matchId')['matchId'].transform('count')\n",
    "    df['killsNorm'] = df['kills']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['maxPlaceNorm'] = df['maxPlace']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['matchDurationNorm'] = df['matchDuration']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['healsandboosts'] = df['heals'] + df['boosts']\n",
    "    df['totalDistance'] = df['rideDistance'] + df['walkDistance'] + df['swimDistance']\n",
    "    df['killsWithoutMoving'] = ((df['kills'] > 0) & (df['totalDistance'] == 0))\n",
    "    df['headshot_rate'] = df['headshotKills'] / df['kills']\n",
    "    df['headshot_rate'] = df['headshot_rate'].fillna(0)\n",
    "    df.drop(df[df['killsWithoutMoving'] == True].index, inplace=True)\n",
    "    df.drop(df[df['roadKills'] > 8].index, inplace=True)\n",
    "                           \n",
    "    \n",
    "\n",
    "    target = 'winPlacePerc'\n",
    "    # Get a list of the features to be used\n",
    "    features = list(df.columns)\n",
    "    \n",
    "    # Remove some features from the features list :\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchDuration\")\n",
    "    features.remove(\"matchType\")\n",
    "    \n",
    "    y = None\n",
    "    \n",
    "    # If we are processing the training data, process the target\n",
    "    # (group the data by the match and the group then take the mean of the target) \n",
    "    if is_train: \n",
    "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
    "        # Remove the target from the features list :\n",
    "        features.remove(target)\n",
    "    \n",
    "    # Make new features indicating the mean of the features ( grouped by match and group ) :\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    \n",
    "    # If we are processing the training data let df_out = the grouped  'matchId' and 'groupId'\n",
    "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    # If we are processing the test data let df_out = 'matchId' and 'groupId' without grouping \n",
    "    else: df_out = df[['matchId','groupId']]\n",
    "    \n",
    "    # Merge agg and agg_rank (that we got before) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the max value of the features for each group ( grouped by match )\n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the minimum value of the features for each group ( grouped by match )\n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the number of players in each group ( grouped by match )\n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "     \n",
    "    # Merge the group_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the mean value of each features for each match :\n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    \n",
    "    # Merge the new agg with df_out :\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    # Make new features indicating the number of groups in each match :\n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    \n",
    "    # Merge the match_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    # Drop matchId and groupId\n",
    "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "    \n",
    "    y = y.tolist()\n",
    "    \n",
    "\n",
    "    return df_out,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_V2.csv\n",
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n"
     ]
    }
   ],
   "source": [
    "#y = trainset[\"winPlacePerc\"]\n",
    "# x = moddedTrain.drop(columns = ['winPlacePerc'])\n",
    "\n",
    "x,y = feature_engineering()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists_mean</th>\n",
       "      <th>boosts_mean</th>\n",
       "      <th>damageDealt_mean</th>\n",
       "      <th>DBNOs_mean</th>\n",
       "      <th>headshotKills_mean</th>\n",
       "      <th>heals_mean</th>\n",
       "      <th>killPlace_mean</th>\n",
       "      <th>killPoints_mean</th>\n",
       "      <th>kills_mean</th>\n",
       "      <th>killStreaks_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>totalDistance</th>\n",
       "      <th>playersJoined</th>\n",
       "      <th>killsNorm</th>\n",
       "      <th>damageDealtNorm</th>\n",
       "      <th>maxPlaceNorm</th>\n",
       "      <th>matchDurationNorm</th>\n",
       "      <th>healsandboosts</th>\n",
       "      <th>killsWithoutMoving</th>\n",
       "      <th>headshot_rate</th>\n",
       "      <th>match_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>381.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.5</td>\n",
       "      <td>1108.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1173.831188</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.926327</td>\n",
       "      <td>138.017345</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1407.60</td>\n",
       "      <td>2.061224</td>\n",
       "      <td>False</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1098.067766</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.081698</td>\n",
       "      <td>130.354608</td>\n",
       "      <td>77.91</td>\n",
       "      <td>1894.83</td>\n",
       "      <td>1.584906</td>\n",
       "      <td>False</td>\n",
       "      <td>0.091195</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722177</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>868.576073</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>141.390925</td>\n",
       "      <td>50.96</td>\n",
       "      <td>1436.24</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.145081</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>885.096579</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.958511</td>\n",
       "      <td>116.455096</td>\n",
       "      <td>99.64</td>\n",
       "      <td>1538.06</td>\n",
       "      <td>1.595745</td>\n",
       "      <td>False</td>\n",
       "      <td>0.102541</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>226.633333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>917.485354</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.018333</td>\n",
       "      <td>143.986158</td>\n",
       "      <td>49.92</td>\n",
       "      <td>1487.20</td>\n",
       "      <td>1.947917</td>\n",
       "      <td>False</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        assists_mean  boosts_mean  damageDealt_mean  DBNOs_mean  \\\n",
       "755194           1.0          3.5        381.850000         1.0   \n",
       "487077           0.0          0.0          0.000000         0.0   \n",
       "722177           0.0          0.0          0.000000         0.0   \n",
       "397616           0.0          0.0         54.180000         0.0   \n",
       "717414           0.0          3.0        226.633333         1.0   \n",
       "\n",
       "        headshotKills_mean  heals_mean  killPlace_mean  killPoints_mean  \\\n",
       "755194                 0.0    1.000000            24.5           1108.5   \n",
       "487077                 0.0    0.000000            29.0           1376.0   \n",
       "722177                 0.0    0.000000            93.5              0.0   \n",
       "397616                 0.0    0.000000            86.0              0.0   \n",
       "717414                 1.0    3.666667            24.0              0.0   \n",
       "\n",
       "        kills_mean  killStreaks_mean     ...      totalDistance  \\\n",
       "755194         1.5               1.0     ...        1173.831188   \n",
       "487077         0.0               0.0     ...        1098.067766   \n",
       "722177         0.0               0.0     ...         868.576073   \n",
       "397616         0.0               0.0     ...         885.096579   \n",
       "717414         2.0               1.0     ...         917.485354   \n",
       "\n",
       "        playersJoined  killsNorm  damageDealtNorm  maxPlaceNorm  \\\n",
       "755194           98.0   0.926327       138.017345         51.00   \n",
       "487077           53.0   1.081698       130.354608         77.91   \n",
       "722177           96.0   0.996667       141.390925         50.96   \n",
       "397616           94.0   0.958511       116.455096         99.64   \n",
       "717414           96.0   1.018333       143.986158         49.92   \n",
       "\n",
       "        matchDurationNorm  healsandboosts  killsWithoutMoving  headshot_rate  \\\n",
       "755194            1407.60        2.061224               False       0.095578   \n",
       "487077            1894.83        1.584906               False       0.091195   \n",
       "722177            1436.24        2.062500               False       0.145081   \n",
       "397616            1538.06        1.595745               False       0.102541   \n",
       "717414            1487.20        1.947917               False       0.067535   \n",
       "\n",
       "        match_size  \n",
       "755194          98  \n",
       "487077          53  \n",
       "722177          96  \n",
       "397616          94  \n",
       "717414          96  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset_dmatrix = xgb.DMatrix(x_train.values,label=y_train,feature_names=x_train.columns)\n",
    "valset_dmatrix = xgb.DMatrix(x_val.values,label=y_val,feature_names=x_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\" : 20,\n",
    "    \"eval_metric\" : [\"mae\"],\n",
    "#     \"eta\" : 0.1,\n",
    "     \"gamma\" : 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:46:28] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 9102 extra nodes, 94758 pruned nodes, max_depth=20\n",
      "[0]\ttrain-mae:0.183088\tval-mae:0.183233\n",
      "[10:47:13] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 7912 extra nodes, 123496 pruned nodes, max_depth=20\n",
      "[1]\ttrain-mae:0.130728\tval-mae:0.131234\n",
      "[10:48:00] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6496 extra nodes, 151776 pruned nodes, max_depth=20\n",
      "[2]\ttrain-mae:0.095004\tval-mae:0.095869\n",
      "[10:48:47] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 5092 extra nodes, 168772 pruned nodes, max_depth=20\n",
      "[3]\ttrain-mae:0.071172\tval-mae:0.072388\n",
      "[10:49:35] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4168 extra nodes, 184216 pruned nodes, max_depth=20\n",
      "[4]\ttrain-mae:0.055697\tval-mae:0.057223\n",
      "[10:50:24] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 3256 extra nodes, 184342 pruned nodes, max_depth=20\n",
      "[5]\ttrain-mae:0.045821\tval-mae:0.04759\n",
      "[10:51:11] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2296 extra nodes, 180976 pruned nodes, max_depth=20\n",
      "[6]\ttrain-mae:0.03959\tval-mae:0.041529\n",
      "[10:52:00] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 1844 extra nodes, 179680 pruned nodes, max_depth=20\n",
      "[7]\ttrain-mae:0.035799\tval-mae:0.037861\n",
      "[10:52:49] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 1458 extra nodes, 173674 pruned nodes, max_depth=20\n",
      "[8]\ttrain-mae:0.033416\tval-mae:0.035564\n",
      "[10:53:36] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 1242 extra nodes, 143458 pruned nodes, max_depth=20\n",
      "[9]\ttrain-mae:0.031895\tval-mae:0.034112\n",
      "[10:54:23] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 1142 extra nodes, 160068 pruned nodes, max_depth=20\n",
      "[10]\ttrain-mae:0.030791\tval-mae:0.033046\n",
      "[10:55:09] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 818 extra nodes, 136432 pruned nodes, max_depth=19\n",
      "[11]\ttrain-mae:0.030124\tval-mae:0.032413\n",
      "[10:55:56] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 862 extra nodes, 145354 pruned nodes, max_depth=20\n",
      "[12]\ttrain-mae:0.029596\tval-mae:0.031918\n",
      "[10:56:42] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 540 extra nodes, 128986 pruned nodes, max_depth=20\n",
      "[13]\ttrain-mae:0.029276\tval-mae:0.031618\n",
      "[10:57:26] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 390 extra nodes, 116280 pruned nodes, max_depth=20\n",
      "[14]\ttrain-mae:0.029061\tval-mae:0.031415\n",
      "[10:58:11] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 506 extra nodes, 124946 pruned nodes, max_depth=20\n",
      "[15]\ttrain-mae:0.028857\tval-mae:0.03123\n",
      "[10:58:56] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 342 extra nodes, 114628 pruned nodes, max_depth=20\n",
      "[16]\ttrain-mae:0.028737\tval-mae:0.031125\n",
      "[10:59:40] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 664 extra nodes, 146078 pruned nodes, max_depth=20\n",
      "[17]\ttrain-mae:0.028562\tval-mae:0.03097\n",
      "[11:00:22] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 346 extra nodes, 84418 pruned nodes, max_depth=20\n",
      "[18]\ttrain-mae:0.028475\tval-mae:0.030894\n",
      "[11:01:05] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 320 extra nodes, 89568 pruned nodes, max_depth=20\n",
      "[19]\ttrain-mae:0.028399\tval-mae:0.030826\n",
      "[11:01:48] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 346 extra nodes, 85770 pruned nodes, max_depth=18\n",
      "[20]\ttrain-mae:0.028322\tval-mae:0.030756\n",
      "[11:02:30] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 420 extra nodes, 90366 pruned nodes, max_depth=19\n",
      "[21]\ttrain-mae:0.028244\tval-mae:0.030693\n",
      "[11:03:12] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 268 extra nodes, 72654 pruned nodes, max_depth=20\n",
      "[22]\ttrain-mae:0.028192\tval-mae:0.030651\n",
      "[11:03:54] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 206 extra nodes, 74530 pruned nodes, max_depth=19\n",
      "[23]\ttrain-mae:0.028166\tval-mae:0.030633\n",
      "[11:04:38] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 156 extra nodes, 86052 pruned nodes, max_depth=19\n",
      "[24]\ttrain-mae:0.028138\tval-mae:0.03061\n",
      "[11:05:21] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 268 extra nodes, 94218 pruned nodes, max_depth=17\n",
      "[25]\ttrain-mae:0.028101\tval-mae:0.030579\n",
      "[11:06:02] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 272 extra nodes, 53340 pruned nodes, max_depth=20\n",
      "[26]\ttrain-mae:0.02805\tval-mae:0.030536\n",
      "[11:06:43] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 196 extra nodes, 56444 pruned nodes, max_depth=19\n",
      "[27]\ttrain-mae:0.028012\tval-mae:0.030502\n",
      "[11:07:27] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 102686 pruned nodes, max_depth=19\n",
      "[28]\ttrain-mae:0.027979\tval-mae:0.030474\n",
      "[11:08:10] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 282 extra nodes, 73440 pruned nodes, max_depth=20\n",
      "[29]\ttrain-mae:0.027931\tval-mae:0.030433\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-de1b0ca73dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalset_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalset_dmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "clf = xgb.train(params, trainset_dmatrix, evals=[(trainset_dmatrix, \"train\"),(valset_dmatrix, 'val')], num_boost_round = 30)\n",
    "\n",
    "predictions = xgb.predict(valset_dmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".031505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove non-important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = moddedTrain[['walkDistance','killPlace','kills','killsNorm','totalDistance','matchDurationNorm','playersJoined','numGroups','matchDuration','boosts','DBNOs','weaponsAcquired','assists','healsandboosts','maxPlaceNorm','killStreaks','longestKill','maxPlace','rankPoints']]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_dmatrix = xgb.DMatrix(x_train.values,label=y_train.values)\n",
    "valset_dmatrix = xgb.DMatrix(x_val.values,label=y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\" : 20,\n",
    "    \"eval_metric\" : [\"mae\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.train(params, trainset_dmatrix, evals=[(trainset_dmatrix, \"train\"),(valset_dmatrix, 'val')], num_boost_round = 20)\n",
    "\n",
    "predictions = xgb.predict(valset_dmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
